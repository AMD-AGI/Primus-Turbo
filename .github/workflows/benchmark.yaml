name: Primus-Turbo-Benchmark

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'

env:
  BENCHMARK_ROOT_DIR: /wekafs/primus_turbo/benchmark

jobs:
  benchmark-pytorch-gfx942:
    runs-on: turbo-pt-bench-gfx942-2510-vsskr
    env:
      GPU_NAME: MI325  # Change this to your GPU model
    steps:
      - run: echo "ðŸŽ‰ Begin Primus-Turbo Benchmark."
      - name: Change owner
        run: |
          echo "change the owner of all primus-turbo files, as some files are generated by root"
          echo "GITHUB_WORKSPACE: ${GITHUB_WORKSPACE}"
          sudo chown -R $(id -u):$(id -g) ${GITHUB_WORKSPACE}
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main
          submodules: 'recursive'
      - name: Print dir
        run: |
          echo "GITHUB_WORKSPACE: ${GITHUB_WORKSPACE}"
          echo "current dir: $(pwd)"
      - name: Install Primus-Turbo
        run: |
          unset AITER_ASM_DIR
          pip3 install -r requirements.txt
          GPU_ARCHS="gfx942" PRIMUS_TURBO_FRAMEWORK="PYTORCH" pip3 install --no-build-isolation -e . -v
      - name: Create benchmark output directory
        run: |
          BENCHMARK_DATE=$(date +%Y%m%d)
          BENCHMARK_OUTPUT_DIR="${BENCHMARK_ROOT_DIR}/${BENCHMARK_DATE}/${GPU_NAME}"
          mkdir -p "${BENCHMARK_OUTPUT_DIR}"
          echo "BENCHMARK_OUTPUT_DIR=${BENCHMARK_OUTPUT_DIR}" >> $GITHUB_ENV
      - name: "[1.1] Run Attention Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_attention.py -o "${BENCHMARK_OUTPUT_DIR}/attention_benchmark.csv"
      - name: "[1.2] Run Attention FP8 Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_attention.py --fp8 -o "${BENCHMARK_OUTPUT_DIR}/attention_fp8_benchmark.csv"
      - name: "[2.1] Run GEMM Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_gemm.py -o "${BENCHMARK_OUTPUT_DIR}/gemm_benchmark.csv"
      - name: "[2.2] Run GEMM FP8 Tensorwise Benchmark (HIPBLASLT Backend)"
        timeout-minutes: 30
        continue-on-error: true
        env:
          PRIMUS_TURBO_GEMM_BACKEND: "HIPBLASLT"
        run: python3 benchmark/ops/bench_gemm_fp8.py --granularity tensorwise -o "${BENCHMARK_OUTPUT_DIR}/gemm_fp8_tensorwise_hipblaslt_benchmark.csv"
      - name: "[2.3] Run GEMM FP8 Tensorwise Benchmark (CK Backend)"
        timeout-minutes: 30
        continue-on-error: true
        env:
          PRIMUS_TURBO_GEMM_BACKEND: "CK"
        run: python3 benchmark/ops/bench_gemm_fp8.py --granularity tensorwise -o "${BENCHMARK_OUTPUT_DIR}/gemm_fp8_tensorwise_ck_benchmark.csv"
      - name: "[2.4] Run GEMM FP8 Tensorwise Benchmark (AutoTune)"
        timeout-minutes: 30
        continue-on-error: true
        env:
          PRIMUS_TURBO_AUTO_TUNE: "1"
        run: python3 benchmark/ops/bench_gemm_fp8.py --granularity tensorwise -o "${BENCHMARK_OUTPUT_DIR}/gemm_fp8_tensorwise_autotune_benchmark.csv"
      - name: "[2.5] Run GEMM FP8 Rowwise Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_gemm_fp8.py --granularity rowwise -o "${BENCHMARK_OUTPUT_DIR}/gemm_fp8_rowwise_benchmark.csv"
      - name: "[2.6] Run GEMM FP8 Blockwise Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_gemm_fp8.py --granularity blockwise -o "${BENCHMARK_OUTPUT_DIR}/gemm_fp8_blockwise_benchmark.csv"
      # - name: Run GEMM FP8 MX Benchmark
      #   timeout-minutes: 30
      #   continue-on-error: true
      #   run: python3 benchmark/ops/bench_gemm_fp8.py --granularity mx -o "${BENCHMARK_OUTPUT_DIR}/gemm_fp8_mx_benchmark.csv"
      - name: "[3.1] Run Grouped GEMM Benchmark (HIPBLASLT Backend)"
        timeout-minutes: 30
        continue-on-error: true
        env:
          PRIMUS_TURBO_GROUPED_GEMM_BACKEND: "HIPBLASLT"
        run: python3 benchmark/ops/bench_grouped_gemm.py -o "${BENCHMARK_OUTPUT_DIR}/grouped_gemm_hipblaslt_benchmark.csv"
      - name: "[3.2] Run Grouped GEMM Benchmark (CK Backend)"
        timeout-minutes: 30
        continue-on-error: true
        env:
          PRIMUS_TURBO_GROUPED_GEMM_BACKEND: "CK"
        run: python3 benchmark/ops/bench_grouped_gemm.py -o "${BENCHMARK_OUTPUT_DIR}/grouped_gemm_ck_benchmark.csv"
      - name: "[3.3] Run Grouped GEMM Benchmark (AutoTune)"
        timeout-minutes: 30
        continue-on-error: true
        env:
          PRIMUS_TURBO_AUTO_TUNE: "1"
        run: python3 benchmark/ops/bench_grouped_gemm.py -o "${BENCHMARK_OUTPUT_DIR}/grouped_gemm_autotune_benchmark.csv"
      - name: "[3.4] Run Grouped GEMM FP8 Tensorwise Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_grouped_gemm_fp8.py --granularity tensorwise -o "${BENCHMARK_OUTPUT_DIR}/grouped_gemm_fp8_tensorwise_benchmark.csv"
      - name: "[3.5] Run Grouped GEMM FP8 Rowwise Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_grouped_gemm_fp8.py --granularity rowwise -o "${BENCHMARK_OUTPUT_DIR}/grouped_gemm_fp8_rowwise_benchmark.csv"
      - name: "[3.6] Run Grouped GEMM FP8 Blockwise Benchmark"
        timeout-minutes: 30
        continue-on-error: true
        run: python3 benchmark/ops/bench_grouped_gemm_fp8.py --granularity blockwise -o "${BENCHMARK_OUTPUT_DIR}/grouped_gemm_fp8_blockwise_benchmark.csv"
